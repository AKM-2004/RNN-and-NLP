{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# There are Two techniques in for in put in nlp\n",
        "## 1) is normal text to numerical (integer Encoding)\n",
        "## 2) is Emnedding"
      ],
      "metadata": {
        "id": "aFFGFAfpVTxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Cknh9WahL53M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "docs =  [\n",
        "    \"go india\",\n",
        "    \"india india\",\n",
        "    \"Hello world i am here\",\n",
        "    \"hip hip hurruy\",\n",
        "    \"bharat mata ki jai\",\n",
        "    \"dhoni dhoni\",\n",
        "    \"modi ji ki jai\",\n",
        "    \"hindustan jindabad\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tonken = Tokenizer(oov_token = \"aditya\") # oov token out of nowhere\n"
      ],
      "metadata": {
        "id": "CJWanKtaNBlS"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tonken.fit_on_texts(docs)"
      ],
      "metadata": {
        "id": "xOlabw6YNocb"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tonken.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zakL8kmoNuPg",
        "outputId": "fdc20f22-0dbe-4f85-f4d6-81543babbf46"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'aditya': 1,\n",
              " 'india': 2,\n",
              " 'hip': 3,\n",
              " 'ki': 4,\n",
              " 'jai': 5,\n",
              " 'dhoni': 6,\n",
              " 'go': 7,\n",
              " 'hello': 8,\n",
              " 'world': 9,\n",
              " 'i': 10,\n",
              " 'am': 11,\n",
              " 'here': 12,\n",
              " 'hurruy': 13,\n",
              " 'bharat': 14,\n",
              " 'mata': 15,\n",
              " 'modi': 16,\n",
              " 'ji': 17,\n",
              " 'hindustan': 18,\n",
              " 'jindabad': 19}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = tonken.texts_to_sequences(docs)"
      ],
      "metadata": {
        "id": "XSDnKCtfNxLz"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import pad_sequences # yaha per padding ke baje se jo bhi vectors thik se ek length ke nahi hai unko padding karke ek hi lenght ka bana deta hai\n",
        "\n",
        "seq = pad_sequences(sequence,padding=\"post\")"
      ],
      "metadata": {
        "id": "Jdd8wpiSOCkU"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJTk-R3BOmHs",
        "outputId": "b644e17f-fd3e-42b6-c698-e20e5d24cb6b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7,  2,  0,  0,  0],\n",
              "       [ 2,  2,  0,  0,  0],\n",
              "       [ 8,  9, 10, 11, 12],\n",
              "       [ 3,  3, 13,  0,  0],\n",
              "       [14, 15,  4,  5,  0],\n",
              "       [ 6,  6,  0,  0,  0],\n",
              "       [16, 17,  4,  5,  0],\n",
              "       [18, 19,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb ## this is dataset which is preprocessed in the keras library\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Flatten,SimpleRNN,Embedding"
      ],
      "metadata": {
        "id": "qnzgrTLTO81N"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)= imdb.load_data()"
      ],
      "metadata": {
        "id": "4sIvVmTtPmi1"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ku5kPr__RrDU"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train= pad_sequences(x_train,padding=\"post\",maxlen=50)\n",
        "x_test = pad_sequences(x_test,padding=\"post\",maxlen=50)\n"
      ],
      "metadata": {
        "id": "z9hiG38FQgPy"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9lDRi3-RzcD",
        "outputId": "1a05f184-b1eb-48a2-d698-1f73bf37314c"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2071,   56,   26,  141,    6,  194, 7486,   18,    4,  226,   22,\n",
              "         21,  134,  476,   26,  480,    5,  144,   30, 5535,   18,   51,\n",
              "         36,   28,  224,   92,   25,  104,    4,  226,   65,   16,   38,\n",
              "       1334,   88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,\n",
              "         15,   16, 5345,   19,  178,   32], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "697ViKlgPxsW"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.add(SimpleRNN(30,return_sequences=False)) ## return_sequences agar true hai to vo mujhe har timestamp pe output dega\n",
        "model.add(Dense(1,activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "qPaA21I8P07c"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = \"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ytEDaps7T2sE"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,epochs=5,validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "id": "wba0Vj-jfrxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding\n",
        "### in nlp word embedding is a term used for the representation of words for text analysis, typically in the form of real-valued that encodes the meaning of the word such that the words closer in the vector space are expecred to be similar in meaning\n",
        "\n",
        "##in NLP word2vec and grove jo hai ya embeeding hi hai"
      ],
      "metadata": {
        "id": "vOkRGlsCVS3e"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DUIxa8PPVrIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb ## this is dataset which is preprocessed in the keras library\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Flatten,SimpleRNN,Embedding"
      ],
      "metadata": {
        "id": "38bGLDOtXXsC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)= imdb.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cGWJ47lXXsC",
        "outputId": "2e70cc73-0dd0-4e8d-ccff-c44a6436b916"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "CCzKReNyXXsC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train= pad_sequences(x_train,padding=\"post\",maxlen=50)\n",
        "x_test = pad_sequences(x_test,padding=\"post\",maxlen=50)\n"
      ],
      "metadata": {
        "id": "rsCdLURZXXsC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "ciE89hwmXZuu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Embedding(10000,2))\n",
        "model.add(SimpleRNN(32,return_sequences=False))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "Sm2RW94VXd4K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer =\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Ksj9Eoi_Xtni"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,epochs=5,validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dG1VuqOcPz8",
        "outputId": "a1d6ede8-ca90-4c3c-a6eb-edda41853853"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 66s 81ms/step - loss: 0.6293 - accuracy: 0.6135 - val_loss: 0.4873 - val_accuracy: 0.7746\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.4003 - accuracy: 0.8232 - val_loss: 0.4305 - val_accuracy: 0.8054\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.3242 - accuracy: 0.8664 - val_loss: 0.4210 - val_accuracy: 0.8094\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.2775 - accuracy: 0.8928 - val_loss: 0.4362 - val_accuracy: 0.8052\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.2418 - accuracy: 0.9092 - val_loss: 0.4686 - val_accuracy: 0.7895\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c0017aa55a0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lxs2lGZgcZRk"
      },
      "execution_count": 80,
      "outputs": []
    }
  ]
}